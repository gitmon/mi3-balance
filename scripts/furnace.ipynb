{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/jonathan/Documents/mi3-balance/build/python')\n",
    "\n",
    "import drjit as dr\n",
    "import mitsuba as mi\n",
    "from drjit.auto import Float, UInt\n",
    "import time\n",
    "\n",
    "mi.set_variant('cuda_ad_rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from furnace_scene import make_scene, visualize_scene\n",
    "\n",
    "color_ref = [0.2, 0.25, 0.7]\n",
    "scene = make_scene(color_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = mi.render(scene)\n",
    "# print(image)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 001 [0.034878]: Loss = [0.00965773], p = [[0.450009, 0.450006, 0.55]]\n",
      "Iteration 002 [0.010365]: Loss = [0.00603595], p = [[0.400506, 0.400708, 0.599355]]\n",
      "Iteration 003 [0.009888]: Loss = [0.00329287], p = [[0.352004, 0.352914, 0.647336]]\n",
      "Iteration 004 [0.009769]: Loss = [0.00141846], p = [[0.305207, 0.307807, 0.69289]]\n",
      "Iteration 005 [0.009837]: Loss = [0.000361694], p = [[0.261043, 0.266973, 0.734604]]\n",
      "Iteration 006 [0.010510]: Loss = [1.15834e-05], p = [[0.220654, 0.232245, 0.770807]]\n",
      "Iteration 007 [0.010019]: Loss = [0.000186456], p = [[0.185296, 0.205262, 0.799903]]\n",
      "Iteration 008 [0.009774]: Loss = [0.000649929], p = [[0.156137, 0.186941, 0.820828]]\n",
      "Iteration 009 [0.009795]: Loss = [0.00116204], p = [[0.133997, 0.177237, 0.833351]]\n",
      "Iteration 010 [0.009800]: Loss = [0.00154144], p = [[0.119176, 0.175328, 0.838017]]\n",
      "Iteration 011 [0.009832]: Loss = [0.00169898], p = [[0.111439, 0.179991, 0.835856]]\n",
      "Iteration 012 [0.009796]: Loss = [0.00163037], p = [[0.110145, 0.189885, 0.828093]]\n",
      "Iteration 013 [0.009732]: Loss = [0.00138678], p = [[0.114421, 0.203699, 0.815976]]\n",
      "Iteration 014 [0.009814]: Loss = [0.00104442], p = [[0.1233, 0.220187, 0.800707]]\n",
      "Iteration 015 [0.009697]: Loss = [0.000681834], p = [[0.135801, 0.238164, 0.783432]]\n",
      "Iteration 016 [0.009928]: Loss = [0.000365257], p = [[0.150962, 0.256497, 0.765248]]\n",
      "Iteration 017 [0.009767]: Loss = [0.000139951], p = [[0.167853, 0.274111, 0.747202]]\n",
      "Iteration 018 [0.009943]: Loss = [2.60875e-05], p = [[0.185578, 0.290022, 0.730279]]\n",
      "Iteration 019 [0.009847]: Loss = [1.87834e-05], p = [[0.203277, 0.30339, 0.715355]]\n",
      "Iteration 020 [0.010630]: Loss = [9.2361e-05], p = [[0.22014, 0.313585, 0.703151]]\n",
      "Iteration 021 [0.010080]: Loss = [0.00020842], p = [[0.235435, 0.320231, 0.694175]]\n",
      "Iteration 022 [0.010220]: Loss = [0.000326083], p = [[0.248539, 0.323224, 0.688694]]\n",
      "Iteration 023 [0.009973]: Loss = [0.000411721], p = [[0.258972, 0.32271, 0.686727]]\n",
      "Iteration 024 [0.010349]: Loss = [0.000445543], p = [[0.266424, 0.319045, 0.688075]]\n",
      "Iteration 025 [0.009856]: Loss = [0.000423713], p = [[0.270763, 0.312745, 0.692355]]\n",
      "Iteration 026 [0.009915]: Loss = [0.000356268], p = [[0.272034, 0.304436, 0.69905]]\n",
      "Iteration 027 [0.009955]: Loss = [0.000262295], p = [[0.270439, 0.29481, 0.70755]]\n",
      "Iteration 028 [0.009758]: Loss = [0.000164033], p = [[0.266308, 0.28459, 0.717189]]\n",
      "Iteration 029 [0.009834]: Loss = [8.13703e-05], p = [[0.26007, 0.274487, 0.727284]]\n",
      "Iteration 030 [0.009785]: Loss = [2.77105e-05], p = [[0.252223, 0.265163, 0.737167]]\n",
      "Iteration 031 [0.009743]: Loss = [7.85388e-06], p = [[0.243307, 0.257188, 0.746224]]\n",
      "Iteration 032 [0.009807]: Loss = [1.80714e-05], p = [[0.233879, 0.251007, 0.753931]]\n",
      "Iteration 033 [0.009868]: Loss = [4.81698e-05], p = [[0.224484, 0.246907, 0.759883]]\n",
      "Iteration 034 [0.009787]: Loss = [8.48864e-05], p = [[0.21563, 0.245011, 0.763821]]\n",
      "Iteration 035 [0.009745]: Loss = [0.000115638], p = [[0.207765, 0.245272, 0.765643]]\n",
      "Iteration 036 [0.009936]: Loss = [0.000131598], p = [[0.201257, 0.247494, 0.765396]]\n",
      "Iteration 037 [0.009820]: Loss = [0.000129361], p = [[0.196367, 0.251355, 0.763268]]\n",
      "Iteration 038 [0.009758]: Loss = [0.000110951], p = [[0.19325, 0.256441, 0.75956]]\n",
      "Iteration 039 [0.009860]: Loss = [8.24191e-05], p = [[0.191943, 0.262282, 0.75466]]\n",
      "Iteration 040 [0.009737]: Loss = [5.16203e-05], p = [[0.192375, 0.268383, 0.749009]]\n",
      "Iteration 041 [0.009988]: Loss = [2.58634e-05], p = [[0.194379, 0.274266, 0.74307]]\n",
      "Iteration 042 [0.009748]: Loss = [1.0049e-05], p = [[0.197705, 0.279501, 0.737294]]\n",
      "Iteration 043 [0.009890]: Loss = [5.71278e-06], p = [[0.202044, 0.283734, 0.73209]]\n",
      "Iteration 044 [0.009698]: Loss = [1.11034e-05], p = [[0.207051, 0.286718, 0.727797]]\n",
      "Iteration 045 [0.009990]: Loss = [2.21484e-05], p = [[0.212361, 0.288318, 0.724663]]\n",
      "Iteration 046 [0.010130]: Loss = [3.39346e-05], p = [[0.21762, 0.288521, 0.722829]]\n",
      "Iteration 047 [0.009756]: Loss = [4.22181e-05], p = [[0.222501, 0.287426, 0.72233]]\n",
      "Iteration 048 [0.009869]: Loss = [4.45265e-05], p = [[0.226723, 0.285229, 0.723093]]\n",
      "Iteration 049 [0.009773]: Loss = [4.05871e-05], p = [[0.230068, 0.282201, 0.724955]]\n",
      "Iteration 050 [0.009729]: Loss = [3.20539e-05], p = [[0.232391, 0.278659, 0.727678]]\n",
      "Iteration 051 [0.010082]: Loss = [2.17123e-05], p = [[0.233623, 0.274942, 0.730975]]\n",
      "Iteration 052 [0.009924]: Loss = [1.24756e-05], p = [[0.233774, 0.271377, 0.734537]]\n",
      "Iteration 053 [0.009803]: Loss = [6.4905e-06], p = [[0.232924, 0.268253, 0.738052]]\n",
      "Iteration 054 [0.009766]: Loss = [4.61e-06], p = [[0.231213, 0.265802, 0.74124]]\n",
      "Iteration 055 [0.009790]: Loss = [6.33257e-06], p = [[0.228831, 0.264182, 0.743864]]\n",
      "Iteration 056 [0.010191]: Loss = [1.01648e-05], p = [[0.225998, 0.263462, 0.745755]]\n",
      "Iteration 057 [0.009919]: Loss = [1.42369e-05], p = [[0.222947, 0.263632, 0.746815]]\n",
      "Iteration 058 [0.009869]: Loss = [1.69441e-05], p = [[0.219911, 0.264601, 0.747025]]\n",
      "Iteration 059 [0.009767]: Loss = [1.74075e-05], p = [[0.217102, 0.266214, 0.746439]]\n",
      "Iteration 060 [0.009785]: Loss = [1.56363e-05], p = [[0.214701, 0.268271, 0.745175]]\n",
      "Iteration 061 [0.009822]: Loss = [1.23782e-05], p = [[0.212846, 0.270546, 0.7434]]\n",
      "Iteration 062 [0.009922]: Loss = [8.75838e-06], p = [[0.211624, 0.272813, 0.741312]]\n",
      "Iteration 063 [0.009764]: Loss = [5.85029e-06], p = [[0.211072, 0.274861, 0.739123]]\n",
      "Iteration 064 [0.009857]: Loss = [4.33024e-06], p = [[0.211172, 0.276518, 0.737034]]\n",
      "Iteration 065 [0.009896]: Loss = [4.31576e-06], p = [[0.211861, 0.277662, 0.735225]]\n",
      "Iteration 066 [0.009996]: Loss = [5.41541e-06], p = [[0.213036, 0.278227, 0.733835]]\n",
      "Iteration 067 [0.009910]: Loss = [6.94076e-06], p = [[0.214569, 0.278209, 0.732953]]\n",
      "Iteration 068 [0.009929]: Loss = [8.18636e-06], p = [[0.21631, 0.277661, 0.732617]]\n",
      "Iteration 069 [0.009828]: Loss = [8.67209e-06], p = [[0.218109, 0.276681, 0.732812]]\n",
      "Iteration 070 [0.009726]: Loss = [8.27094e-06], p = [[0.219823, 0.275403, 0.733471]]\n",
      "Iteration 071 [0.009819]: Loss = [7.19363e-06], p = [[0.221326, 0.273979, 0.734495]]\n",
      "Iteration 072 [0.009896]: Loss = [5.86005e-06], p = [[0.222518, 0.272563, 0.735753]]\n",
      "Iteration 073 [0.009776]: Loss = [4.71639e-06], p = [[0.223333, 0.271295, 0.737107]]\n",
      "Iteration 074 [0.009785]: Loss = [4.0728e-06], p = [[0.223739, 0.270291, 0.738418]]\n",
      "Iteration 075 [0.009690]: Loss = [4.01442e-06], p = [[0.223739, 0.269629, 0.739564]]\n",
      "Iteration 076 [0.009822]: Loss = [4.40747e-06], p = [[0.223369, 0.269348, 0.740448]]\n",
      "Iteration 077 [0.009802]: Loss = [4.98273e-06], p = [[0.222691, 0.269442, 0.741006]]\n",
      "Iteration 078 [0.009814]: Loss = [5.45508e-06], p = [[0.221787, 0.269869, 0.741213]]\n",
      "Iteration 079 [0.009896]: Loss = [5.62978e-06], p = [[0.220753, 0.270555, 0.741078]]\n",
      "Iteration 080 [0.009788]: Loss = [5.45889e-06], p = [[0.219684, 0.271405, 0.740645]]\n",
      "Iteration 081 [0.009880]: Loss = [5.03397e-06], p = [[0.218672, 0.272315, 0.739985]]\n",
      "Iteration 082 [0.009724]: Loss = [4.5292e-06], p = [[0.217798, 0.273183, 0.739183]]\n",
      "Iteration 083 [0.009831]: Loss = [4.12163e-06], p = [[0.217123, 0.27392, 0.738334]]\n",
      "Iteration 084 [0.010001]: Loss = [3.92396e-06], p = [[0.216686, 0.274458, 0.737529]]\n",
      "Iteration 085 [0.009886]: Loss = [3.95231e-06], p = [[0.216503, 0.274757, 0.736846]]\n",
      "Iteration 086 [0.010068]: Loss = [4.13586e-06], p = [[0.216568, 0.274804, 0.736347]]\n",
      "Iteration 087 [0.009822]: Loss = [4.35831e-06], p = [[0.216853, 0.274618, 0.736065]]\n",
      "Iteration 088 [0.010006]: Loss = [4.51002e-06], p = [[0.217314, 0.27424, 0.736012]]\n",
      "Iteration 089 [0.010365]: Loss = [4.52943e-06], p = [[0.217894, 0.273728, 0.736173]]\n",
      "Iteration 090 [0.009722]: Loss = [4.41861e-06], p = [[0.218532, 0.273152, 0.736511]]\n",
      "Iteration 091 [0.009998]: Loss = [4.2318e-06], p = [[0.219166, 0.272583, 0.736975]]\n",
      "Iteration 092 [0.010080]: Loss = [4.04499e-06], p = [[0.21974, 0.272084, 0.737503]]\n",
      "Iteration 093 [0.009854]: Loss = [3.92232e-06], p = [[0.220209, 0.271705, 0.738033]]\n",
      "Iteration 094 [0.010170]: Loss = [3.89209e-06], p = [[0.220539, 0.271479, 0.738507]]\n",
      "Iteration 095 [0.009735]: Loss = [3.94161e-06], p = [[0.220713, 0.271418, 0.738878]]\n",
      "Iteration 096 [0.009899]: Loss = [4.02905e-06], p = [[0.220729, 0.271514, 0.739115]]\n",
      "Iteration 097 [0.009976]: Loss = [4.10524e-06], p = [[0.220601, 0.271743, 0.739204]]\n",
      "Iteration 098 [0.009784]: Loss = [4.13475e-06], p = [[0.220352, 0.272064, 0.739148]]\n",
      "Iteration 099 [0.009987]: Loss = [4.10812e-06], p = [[0.220017, 0.272433, 0.738967]]\n",
      "Iteration 100 [0.009764]: Loss = [4.04115e-06], p = [[0.219635, 0.272802, 0.738692]]\n"
     ]
    }
   ],
   "source": [
    "from radiosity import SceneSurfaceSampler, RadianceCacheMITSUBA, compute_loss\n",
    "\n",
    "NUM_WI_DIRECTIONS = 16\n",
    "SAMPLES_PER_RAY_LI = 32\n",
    "SAMPLES_PER_RAY_LO = 32\n",
    "NUM_GEO_SAMPLES = 2\n",
    "\n",
    "scene_sampler = SceneSurfaceSampler(scene)\n",
    "radiance_cache = RadianceCacheMITSUBA(scene)\n",
    "\n",
    "# Initialize BSDF to train\n",
    "bsdf_train = mi.load_dict({\n",
    "    \"type\": \"diffuse\",\n",
    "    \"reflectance\": {\n",
    "        \"type\": \"rgb\",\n",
    "        \"value\": [0.5, 0.5, 0.5]\n",
    "    }\n",
    "})\n",
    "\n",
    "params = mi.traverse(bsdf_train)\n",
    "opt = mi.ad.Adam(lr=0.05)\n",
    "key = \"reflectance.value\"\n",
    "dr.enable_grad(params[key])\n",
    "opt[key] = params[key]\n",
    "params.update(opt)\n",
    "\n",
    "for it in range(100):\n",
    "\n",
    "    # if True: ## Temp workaround\n",
    "    #     # Initialize samplers\n",
    "    #     scalar_sampler = mi.load_dict({\n",
    "    #                 'type': 'independent',\n",
    "    #                 'sample_count': 1\n",
    "    #             })\n",
    "    #     scalar_sampler.seed(it, 1)\n",
    "\n",
    "    time1 = time.time()\n",
    "\n",
    "    # Evaluate the objective function for the current BSDF params\n",
    "    loss = compute_loss(scene_sampler, radiance_cache, bsdf_train, \n",
    "        NUM_GEO_SAMPLES, NUM_WI_DIRECTIONS, \n",
    "        SAMPLES_PER_RAY_LO, SAMPLES_PER_RAY_LI)\n",
    "\n",
    "    # Backpropagate through the rendering process\n",
    "    dr.backward(loss)\n",
    "\n",
    "    # Optimizer: take a gradient descent step\n",
    "    opt.step()\n",
    "\n",
    "    # Post-process the optimized parameters to ensure legal color values.\n",
    "    opt[key] = dr.clip(opt[key], 0.0, 1.0)\n",
    "\n",
    "    # Update the scene state to the new optimized values\n",
    "    params.update(opt)\n",
    "\n",
    "    # losses.append(dr.detach(loss))\n",
    "    time2 = time.time()\n",
    "    print(f\"Iteration {1+it:03d} [{time2 - time1:2f}]: Loss = {loss}, p = {opt[key]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SmoothDiffuse[\n",
      "  reflectance = SRGBReflectanceSpectrum[\n",
      "    value = [[0.219635, 0.272802, 0.738692]]\n",
      "  ]\n",
      "]\n",
      "[0.2, 0.25, 0.7]\n"
     ]
    }
   ],
   "source": [
    "print(bsdf_train)\n",
    "print(color_ref)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "balance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
